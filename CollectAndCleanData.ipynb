{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ongoing-relationship",
   "metadata": {},
   "source": [
    "# Data Collection and Cleaning (A3 and A4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "administrative-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from Kafka import KafkaWriter, KafkaReader\n",
    "from OpenWeatherMap import OpenWeatherMap\n",
    "import datetime\n",
    "import time\n",
    "from CheckDuplicates import check_if_duplicate, check_if_duplicate_in_list\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exact-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "openWeatherMap = OpenWeatherMap(api_key=\"2265d775d28c3c75d22edcb7126ca08f\") # enter your api key here\n",
    "kafka_prod1 = KafkaWriter(bootstrap_servers='kafka-1,kafka-2', topic='weather.forecast.raw') # enter bootstrap servers and topic\n",
    "\n",
    "def load_locations() -> json:\n",
    "    \"\"\"\n",
    "    Loads 'locations.json' into a json-object and returns it.\n",
    "    \"\"\"\n",
    "    with open('locations.json', mode='r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def collect_forecast_data() -> None:\n",
    "    \"\"\"\n",
    "    Queries OpenWeatherMap for each location for the 5-day forecast and stores the the returned values in Kafka.\n",
    "    \"\"\"\n",
    "    locs = load_locations()\n",
    "    dt_format = \"%Y%m%d%H%M%S\"\n",
    "    for loc in locs: # for each location\n",
    "        city = locs[loc]\n",
    "        data = openWeatherMap.get_forecast(city=city) # query OpenWeatherMap\n",
    "        for element in data['list']: # for each forecast\n",
    "            element['city'] = {'name': loc, 'coords': {'latitude': city['latitude'], 'longitude': city['longitude']}} # add city (name + coords)\n",
    "            element['fetched_at'] = int(datetime.datetime.now().strftime(dt_format)) # create own timestamp and add it to the forecast\n",
    "            key = uuid.uuid4().hex\n",
    "            kafka_prod1.store(message_key=key, data=element) # publish forecast data with unique key to Kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_con1 = KafkaReader(bootstrap_servers='kafka-1,kafka-2', topic='weather.forecast.raw', group_id='con_group1', client_id='con1', auto_offset_reset='latest')\n",
    "kafka_prod2 = KafkaWriter(bootstrap_servers='kafka-1,kafka-2', topic='weather.forecast.clean')\n",
    "\n",
    "def clean_forecast_data() -> None:\n",
    "    \"\"\"\n",
    "    Consumes new raw forecast data from corresponding topic, compares it to the data that is already stored in the \"cleaned\" topic and adds missing forecasts to the \"cleaned\" topic.\n",
    "    This process leads to the \"cleaned\" topic containing no duplicates.\n",
    "    \"\"\"\n",
    "    raw_data = kafka_con1.retrieve() # consume new raw data\n",
    "    old_clean_data = KafkaReader(bootstrap_servers='kafka-1,kafka-2', topic='weather.forecast.clean', group_id=uuid.uuid4().hex, client_id=uuid.uuid4().hex).retrieve() # use new consumer in each iteration to always fetch all old \"cleaned\" data\n",
    "    new_clean_data = [x for x in raw_data if not check_if_duplicate_in_list(new=x, old=old_clean_data)] # compare data in cleaned topic and new raw data, add only to list if raw forecast not already in cleaned topic\n",
    "    for element in new_clean_data:\n",
    "        key = uuid.uuid4().hex\n",
    "        kafka_prod2.store(message_key=key, data=element) # publish each new (unique) forecast to Kafka topic (cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atomic-miller",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-432b5121e82f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcollect_forecast_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# collect raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclean_forecast_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clean datas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# every 15 Minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True: # endless loop\n",
    "    collect_forecast_data() # collect raw data\n",
    "    clean_forecast_data()  # clean datas\n",
    "    time.sleep(15*60)  # e.g. every 15 Minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
